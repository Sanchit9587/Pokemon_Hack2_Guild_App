{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdVuY/FuaoEecXUY4Z8v7W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sanchit9587/Pokemon_Hack2_Guild_App/blob/NER%26NLP/Inference_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.41.2\n",
        "!pip install torch==2.3.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY9O8-7zIOkU",
        "outputId": "28f00c5c-2466-43f8-a3a0-67756fa9e00d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.41.2 in /usr/local/lib/python3.12/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (1.1.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.41.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.41.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.41.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.41.2) (2025.8.3)\n",
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.12/dist-packages (2.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import torch\n",
        "from transformers import BertTokenizerFast, BertForTokenClassification"
      ],
      "metadata": {
        "id": "PVmtTWKTIWm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Step 1: Setting up configuration...\")\n",
        "\n",
        "# --- Configuration Block ---\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DRIVE_MOUNT_PATH = \"/content/drive\"\n",
        "MODEL_PATH = os.path.join(DRIVE_MOUNT_PATH, \"MyDrive/PokemonNERModel\")\n",
        "\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "print(f\"Loading model from: {MODEL_PATH}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. Mount Google Drive\n",
        "# ==============================================================================\n",
        "print(\"\\nStep 2: Mounting Google Drive...\")\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(DRIVE_MOUNT_PATH, force_remount=True)\n",
        "    print(\"Google Drive mounted successfully.\")\n",
        "except ImportError:\n",
        "    print(\"Not in a Colab environment. Skipping Google Drive mount.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during drive mounting: {e}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. Load Model, Tokenizer, and Label Mappings\n",
        "# ==============================================================================\n",
        "print(\"\\nStep 3: Loading model and tokenizer...\")\n",
        "\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    print(\"\\n!!! ERROR !!!\")\n",
        "    print(f\"Model directory not found at '{MODEL_PATH}'.\")\n",
        "    print(\"Please ensure your model was saved correctly to your Google Drive.\")\n",
        "else:\n",
        "    try:\n",
        "        model = BertForTokenClassification.from_pretrained(MODEL_PATH)\n",
        "        tokenizer = BertTokenizerFast.from_pretrained(MODEL_PATH)\n",
        "        model.to(DEVICE)\n",
        "        model.eval() # Set the model to evaluation mode\n",
        "\n",
        "        # Load the tag mappings created during training\n",
        "        with open(os.path.join(MODEL_PATH, 'tag_mappings.json'), 'r') as f:\n",
        "            mappings = json.load(f)\n",
        "            id2tag = mappings['id2tag']\n",
        "            # Convert keys from string back to integer\n",
        "            id2tag = {int(k): v for k, v in id2tag.items()}\n",
        "\n",
        "        print(\"Fine-tuned model, tokenizer, and label mappings loaded successfully.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while loading the model: {e}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. Inference Function\n",
        "# ==============================================================================\n",
        "print(\"\\nStep 4: Defining the inference function...\")\n",
        "\n",
        "def get_pokemon_entities(text):\n",
        "    \"\"\"\n",
        "    Performs NER on a given text and extracts only the enemy and friendly species.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input military-style prompt.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with 'enemy_species' and 'friendly_species' lists.\n",
        "    \"\"\"\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=256\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    # Get model predictions\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "\n",
        "    predictions = torch.argmax(logits, dim=2)\n",
        "    predicted_token_class = [id2tag[p.item()] for p in predictions[0]]\n",
        "\n",
        "    # Reconstruct words from subword tokens and align labels\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "\n",
        "    current_word = ''\n",
        "    current_tag = 'O'\n",
        "    words_and_tags = []\n",
        "\n",
        "    for token, tag in zip(tokens, predicted_token_class):\n",
        "        if token in ('[CLS]', '[SEP]', '[PAD]'):\n",
        "            continue\n",
        "\n",
        "        if token.startswith(\"##\"):\n",
        "            current_word += token[2:]\n",
        "        else:\n",
        "            # New word starts, so we process the previous word\n",
        "            if current_word:\n",
        "                words_and_tags.append((current_word, current_tag))\n",
        "\n",
        "            current_word = token\n",
        "            current_tag = tag\n",
        "\n",
        "    # Add the last processed word\n",
        "    if current_word:\n",
        "        words_and_tags.append((current_word, current_tag))\n",
        "\n",
        "    # Extract entities\n",
        "    enemy_species = []\n",
        "    friendly_species = []\n",
        "\n",
        "    for word, tag in words_and_tags:\n",
        "        if tag == 'B-ENEMY_SPECIES':\n",
        "            enemy_species.append(word)\n",
        "        elif tag == 'B-FRIENDLY_SPECIES':\n",
        "            friendly_species.append(word)\n",
        "\n",
        "    return {\n",
        "        \"enemy_species\": list(set(enemy_species)), # Use set to get unique names\n",
        "        \"friendly_species\": list(set(friendly_species))\n",
        "    }\n",
        "\n",
        "print(\"Inference function is ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFIVmh3uIcIZ",
        "outputId": "30adde41-8608-4867-a079-0864abf63066"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Setting up configuration...\n",
            "Using device: cpu\n",
            "Loading model from: /content/drive/MyDrive/PokemonNERModel\n",
            "\n",
            "Step 2: Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully.\n",
            "\n",
            "Step 3: Loading model and tokenizer...\n",
            "Fine-tuned model, tokenizer, and label mappings loaded successfully.\n",
            "\n",
            "Step 4: Defining the inference function...\n",
            "Inference function is ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_pokemon_entities(\"\"\"HQ has detected unusual Bulbasaur activity in the area. Field\n",
        "sensors logged anomalous behavior that suggests an imminent\n",
        "threat. Remember there are Pikachu and Charizard nearby —\n",
        "take care not to draw them into combat. You are to neutralize\n",
        "the bulbasaurs immediately. Report status once the target is\n",
        "down. Confirm mission status and any collateral damages\"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yomj9JdIc3Z",
        "outputId": "9f073b85-8b64-48da-c23c-2c14074316cb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'enemy_species': ['bulbasaurs'], 'friendly_species': ['Charizard', 'Pikachu', 'Bulbasaur']}\n"
          ]
        }
      ]
    }
  ]
}